{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SujayDas1999/Neural-network/blob/main/Sentiment_Analysis_Finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1824d5-2518-4687-9d38-caeb019f4b4b",
      "metadata": {
        "id": "eb1824d5-2518-4687-9d38-caeb019f4b4b"
      },
      "outputs": [],
      "source": [
        "!pip install transformers peft evaluate torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c0a2bfd-dbfa-4fab-8188-f23f7767ac22",
      "metadata": {
        "id": "0c0a2bfd-dbfa-4fab-8188-f23f7767ac22"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "datasets, transformers, peft & evaluate are hugging face libs\n",
        "'''\n",
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8baafb-5726-41e2-a521-a14202f61ac2",
      "metadata": {
        "id": "3c8baafb-5726-41e2-a521-a14202f61ac2"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('shawhin/imdb-truncated')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f191788b-ad79-4d25-817f-ef0cb1589f81",
      "metadata": {
        "id": "f191788b-ad79-4d25-817f-ef0cb1589f81"
      },
      "outputs": [],
      "source": [
        "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7e6155-9b21-4607-90f7-c4e6c8e00139",
      "metadata": {
        "id": "ee7e6155-9b21-4607-90f7-c4e6c8e00139"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Choose a model which you want to fine tune,\n",
        "for example here I have taken bert model\n",
        "\n",
        "Use hugging-face library to fetch the model\n",
        "Since I am doing a sentiment analysis, I am passing few params\n",
        "model_checkpoint = model name\n",
        "num_labels = number of labels ('Positive'/'Negative')\n",
        "id2label & label2id\n",
        "'''\n",
        "model_checkpoint = 'distilbert-base-uncased'\n",
        "\n",
        "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
        "label2id = {\"Negative\":0, \"Positive\":1}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9ec594-c3bd-451d-a81e-27bca97571bc",
      "metadata": {
        "id": "8b9ec594-c3bd-451d-a81e-27bca97571bc"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    print('in here')\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bdecf29-0398-419a-9b08-e072fbb02ac7",
      "metadata": {
        "id": "1bdecf29-0398-419a-9b08-e072fbb02ac7"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    text = example['text']\n",
        "\n",
        "    tokenizer.truncation_side = \"left\"\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4392656f-6578-48a0-b81a-c8f0547a2fcd",
      "metadata": {
        "id": "4392656f-6578-48a0-b81a-c8f0547a2fcd"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb589be5-f031-440c-bedf-4fd8732631f7",
      "metadata": {
        "id": "fb589be5-f031-440c-bedf-4fd8732631f7"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6802640f-bf6c-4b8d-884a-3c5afb64af7b",
      "metadata": {
        "id": "6802640f-bf6c-4b8d-884a-3c5afb64af7b"
      },
      "outputs": [],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "# define an evaluation function to pass into trainer later\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}\n",
        "\n",
        "\n",
        "# define list of examples\n",
        "text_list = [\"It was good.\", \"Woah!! its amazing\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\"]\n",
        "\n",
        "print(\"Untrained model predictions:\")\n",
        "print(\"----------------------------\")\n",
        "for text in text_list:\n",
        "    # tokenize text\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    # compute logits\n",
        "    logits = model(inputs).logits\n",
        "    # convert logits to label\n",
        "    predictions = torch.argmax(logits)\n",
        "\n",
        "    print(text + \" - \" + id2label[predictions.tolist()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dbc10a6-70a2-42b3-a6da-17efececff1b",
      "metadata": {
        "id": "5dbc10a6-70a2-42b3-a6da-17efececff1b"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
        "                        r=4,\n",
        "                        lora_alpha=32,\n",
        "                        lora_dropout=0.01,\n",
        "                        target_modules = ['q_lin'])\n",
        "peft_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77a22f6-46d6-4343-9fa1-316b0ff039a3",
      "metadata": {
        "id": "e77a22f6-46d6-4343-9fa1-316b0ff039a3"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc89522-fb7a-408b-aa56-fd33d48977e5",
      "metadata": {
        "id": "3bc89522-fb7a-408b-aa56-fd33d48977e5"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "batch_size = 4\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3236494a-fefc-42e0-a42f-7642a3ce0d60",
      "metadata": {
        "id": "3236494a-fefc-42e0-a42f-7642a3ce0d60"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= model_checkpoint + \"-lora-text-classification\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f1f7bc-844d-4317-8520-70e9128c8794",
      "metadata": {
        "id": "81f1f7bc-844d-4317-8520-70e9128c8794"
      },
      "outputs": [],
      "source": [
        "!pip install peft==0.10.0 transformers==4.41.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8895fb-b574-4e16-bba7-592ffe9fcdff",
      "metadata": {
        "collapsed": true,
        "id": "ba8895fb-b574-4e16-bba7-592ffe9fcdff"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# train model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a0fd03-50ae-42df-82ba-e0e85409f111",
      "metadata": {
        "id": "a5a0fd03-50ae-42df-82ba-e0e85409f111"
      },
      "outputs": [],
      "source": [
        "model.to('cuda')\n",
        "\n",
        "print(\"Trained model predictions:\")\n",
        "print(\"--------------------------\")\n",
        "text_list = [\"It was good.\", \"Did not find it interesting\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\"]\n",
        "for text in text_list:\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "    logits = model(inputs).logits\n",
        "    predictions = torch.max(logits,1).indices\n",
        "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yZ9N1GxfUoad"
      },
      "id": "yZ9N1GxfUoad",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}